import os
import json
import time
import hashlib
import pandas as pd
import streamlit as st
from openai import OpenAI

# =========================
# PAGE
# =========================
st.set_page_config(page_title="Product Content Generator", layout="wide")
st.title("Ù…ÙˆÙ„Ù‘Ø¯ Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ£ÙˆØµØ§Ù Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª (CSV + Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¨Ø§Ø´Ø±)")

st.caption("Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ â†’ ÙˆÙ„Ù‘Ø¯ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„ÙˆØµÙ â†’ Ù†Ø²Ù‘Ù„ CSV Ø§Ù„Ù†Ø§ØªØ¬")

# =========================
# API KEY (Streamlit Secrets)
# =========================
api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("OPENAI_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø£Ø¶ÙÙ‡ ÙÙŠ Streamlit Secrets Ø£Ùˆ ÙƒÙ…ØªØºÙŠØ± Ø¨ÙŠØ¦Ø©.")
    st.stop()

client = OpenAI(api_key=api_key)

# =========================
# SETTINGS
# =========================
MODEL = st.selectbox("Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„", ["gpt-4.1-mini", "gpt-4.1"], index=0)
temperature = st.slider("Temperature", 0.0, 1.0, 0.7, 0.05)

SYSTEM_PROMPT = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù…Ø­ØªÙˆÙ‰ Ù…Ù†ØªØ¬Ø§Øª Ù„Ø³ÙˆØ¨Ø±Ù…Ø§Ø±ÙƒØª Ø¹Ø±Ø¨ÙŠ ÙƒØ¨ÙŠØ±.
Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: ÙƒØªØ§Ø¨Ø© Ø¹Ù†ÙˆØ§Ù† ÙˆÙˆØµÙ Ø¹Ø±Ø¨ÙŠÙŠÙ† Ø£ØµÙ„ÙŠÙŠÙ† ÙˆÙ‚Ø§Ø¨Ù„ÙŠÙ† Ù„Ù„ÙÙ‡Ø±Ø³Ø©.
Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø¨Ø§Ø±Ø§Øª Ø¹Ø§Ù…Ø© Ù†Ù…Ø·ÙŠØ© ÙˆÙ…ØªÙƒØ±Ø±Ø© Ù…Ø«Ù„: "Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø¨Ù…ÙˆØ§ØµÙØ§Øª ÙˆØ§Ø¶Ø­Ø©".
Ù„Ø§ ØªÙØªØ±Ø¶ Ø§Ø¯Ø¹Ø§Ø¡Ø§Øª ØºÙŠØ± Ù…Ø¤ÙƒØ¯Ø© (Ù…Ø«Ù„: Ø§Ù„Ø£ÙØ¶Ù„/Ø§Ù„Ø£Ø¬ÙˆØ¯/ÙŠØ¹Ø§Ù„Ø¬/ÙŠØ­Ø³Ù† Ø§Ù„ØµØ­Ø©) Ø¥Ù† Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: ÙˆØ§Ø¶Ø­ØŒ Ø¨Ø´Ø±ÙŠØŒ Ù…Ø¨Ø§Ø´Ø±ØŒ Ø¨Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ©.
"""

JSON_SCHEMA = {
    "name": "product_content",
    "schema": {
        "type": "object",
        "additionalProperties": False,
        "properties": {
            "title": {"type": "string", "minLength": 10, "maxLength": 95},
            "description": {"type": "string", "minLength": 140, "maxLength": 1300},
        },
        "required": ["title", "description"],
    },
}

# =========================
# HELPERS
# =========================
def norm(x):
    return str(x).strip() if x is not None else ""

def stable_key(row: dict) -> str:
    base = "|".join([
        norm(row.get("raw_name") or row.get("name")),
        norm(row.get("brand")),
        norm(row.get("product_type")),
        norm(row.get("feature")),
        norm(row.get("size")),
        norm(row.get("unit")),
    ])
    return hashlib.md5(base.encode("utf-8")).hexdigest()

def build_user_input(row: dict) -> str:
    raw_name = norm(row.get("raw_name") or row.get("name"))

    parts = [f"Ø§Ø³Ù… Ø®Ø§Ù…: {raw_name}"]

    optional_fields = [
        ("brand", "Ø§Ù„Ù…Ø§Ø±ÙƒØ©"),
        ("product_type", "Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬"),
        ("feature", "Ø§Ù„Ø®Ø§ØµÙŠØ©/Ø§Ù„Ù†ÙƒÙ‡Ø©"),
        ("size", "Ø§Ù„Ø­Ø¬Ù…"),
        ("unit", "Ø§Ù„ÙˆØ­Ø¯Ø©"),
        ("country", "Ø¨Ù„Ø¯ Ø§Ù„Ù…Ù†Ø´Ø£"),
        ("storage", "Ø§Ù„ØªØ®Ø²ÙŠÙ†"),
        ("shelf_life", "Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©"),
        ("ingredients", "Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª"),
        ("uses", "Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª (Ø¥Ù† ÙˆÙØ¬Ø¯Øª)"),
    ]

    for k, label in optional_fields:
        v = norm(row.get(k))
        if v:
            parts.append(f"{label}: {v}")

    parts.append("""
Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
1) title: Ø¹Ù†ÙˆØ§Ù† SEO-friendly Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨ØµÙŠØºØ© Ø·Ø¨ÙŠØ¹ÙŠØ©:
   (Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬ + Ø§Ù„Ù…Ø§Ø±ÙƒØ© + Ø§Ù„Ø®Ø§ØµÙŠØ© + Ø§Ù„Ø­Ø¬Ù…/Ø§Ù„ÙˆØ­Ø¯Ø©) Ø¹Ù†Ø¯ ØªÙˆÙØ±Ù‡Ø§.
2) description:
   - 2 Ø¥Ù„Ù‰ 4 Ø¬Ù…Ù„ Ù…ÙÙŠØ¯Ø© ÙˆÙ…Ø­Ø¯Ø¯Ø© (Ø¨Ø¯ÙˆÙ† Ø¬Ù…Ù„ Ø¹Ø§Ù…Ø© Ù…ÙƒØ±Ø±Ø©)
   - Ø«Ù… "Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª:" 3 Ù†Ù‚Ø§Ø· (Ø¥Ù† Ù„Ù… ØªØªÙˆÙØ±ØŒ Ø§Ø³ØªÙ†ØªØ¬ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª Ù…Ù†Ø·Ù‚ÙŠØ© Ø¨Ø¯ÙˆÙ† Ø§Ø¯Ø¹Ø§Ø¡Ø§Øª)
   - Ø«Ù… "Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª:" Ù†Ù‚Ø§Ø· Ù‚ØµÙŠØ±Ø© (Ø§Ù„Ù…Ø§Ø±ÙƒØ©/Ø§Ù„Ù†ÙˆØ¹/Ø§Ù„Ø­Ø¬Ù…/Ø§Ù„Ù…Ù†Ø´Ø£/Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø¥Ù† ØªÙˆÙØ±)
""")
    return "\n".join(parts).strip()

def call_openai_structured(user_input: str, max_retries: int = 6) -> dict:
    for attempt in range(max_retries):
        try:
            resp = client.responses.create(
                model=MODEL,
                input=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_input},
                ],
                text={"format": {"type": "json_schema", "json_schema": JSON_SCHEMA}},
                temperature=temperature,
            )
            return json.loads(resp.output_text)
        except Exception as e:
            wait = 1.5 * (2 ** attempt)
            time.sleep(wait)
    raise RuntimeError("Failed after retries")

def to_dataframe_from_list(lines: str) -> pd.DataFrame:
    items = []
    for ln in (lines or "").splitlines():
        ln = ln.strip()
        if ln:
            items.append({"raw_name": ln})
    return pd.DataFrame(items)

def to_dataframe_from_text_csv(csv_text: str) -> pd.DataFrame:
    # ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ pandas Ù„Ù‚Ø±Ø§Ø¡Ø© Ù†Øµ CSV Ù…Ù† Ù…Ø±Ø¨Ø¹ Ø§Ù„Ù†Øµ
    import io
    return pd.read_csv(io.StringIO(csv_text), encoding="utf-8")

# =========================
# INPUT MODE
# =========================
mode = st.radio(
    "Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª",
    ["Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¨Ø§Ø´Ø± (ÙƒÙ„ Ø³Ø·Ø± Ù…Ù†ØªØ¬)", "Ù„ØµÙ‚ CSV ÙƒÙ†Øµ", "Ø±ÙØ¹ Ù…Ù„Ù CSV"],
    horizontal=True
)

df = None

if mode == "Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¨Ø§Ø´Ø± (ÙƒÙ„ Ø³Ø·Ø± Ù…Ù†ØªØ¬)":
    st.subheader("Ø§Ù„ØµÙ‚ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ù‡Ù†Ø§")
    st.caption("ÙƒÙ„ Ø³Ø·Ø± = Ø§Ø³Ù… Ù…Ù†ØªØ¬ Ø®Ø§Ù…. Ù…Ø«Ø§Ù„: Ø§Ù„Ù…Ø±Ø§Ø¹ÙŠ Ø­Ù„ÙŠØ¨ ÙƒØ§Ù…Ù„ Ø§Ù„Ø¯Ø³Ù… 1 Ù„ØªØ±")
    text = st.text_area("Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª", height=220, placeholder="Ø§ÙƒØªØ¨/Ø§Ù„ØµÙ‚ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ù‡Ù†Ø§...")
    df = to_dataframe_from_list(text)

elif mode == "Ù„ØµÙ‚ CSV ÙƒÙ†Øµ":
    st.subheader("Ø§Ù„ØµÙ‚ Ù…Ø­ØªÙˆÙ‰ CSV Ù‡Ù†Ø§")
    st.caption("Ø§Ù„ØµÙ‚ CSV ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‡ÙŠØ¯Ø± (Ù…Ø«Ø§Ù„: raw_name,brand,product_type,size,unit ...)")
    csv_text = st.text_area("CSV Ù†ØµÙ‘ÙŠ", height=260, placeholder="raw_name,brand,product_type,size,unit\n...")
    if csv_text.strip():
        try:
            df = to_dataframe_from_text_csv(csv_text)
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© CSV Ø§Ù„Ù†ØµÙŠ: {e}")
            df = None

else:
    uploaded = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV", type=["csv"])
    if uploaded:
        df = pd.read_csv(uploaded, encoding="utf-8-sig")

# =========================
# COLUMN MAPPING
# =========================
if df is not None:
    st.divider()
    st.success(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù‘Ù„Ø©: {len(df):,}")

    if len(df) == 0:
        st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£ÙŠ Ù…Ù†ØªØ¬Ø§Øª Ø¨Ø¹Ø¯. Ø£Ø¶Ù Ù…Ù†ØªØ¬Ø§Øª Ø«Ù… ØªØ§Ø¨Ø¹.")
        st.stop()

    cols = list(df.columns)

    st.subheader("Ø±Ø¨Ø· Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Column Mapping)")
    col_name = st.selectbox("Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬", cols, index=cols.index("raw_name") if "raw_name" in cols else 0)

    def opt_col(label):
        return st.selectbox(label, [""] + cols, index=0)

    col_brand   = opt_col("Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø§Ø±ÙƒØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    col_type    = opt_col("Ø¹Ù…ÙˆØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    col_feature = opt_col("Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø®Ø§ØµÙŠØ©/Ø§Ù„Ù†ÙƒÙ‡Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    col_size    = opt_col("Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø­Ø¬Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    col_unit    = opt_col("Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙˆØ­Ø¯Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    col_country = opt_col("Ø¹Ù…ÙˆØ¯ Ø¨Ù„Ø¯ Ø§Ù„Ù…Ù†Ø´Ø£ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    col_storage = opt_col("Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ®Ø²ÙŠÙ† (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    col_uses    = opt_col("Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")

    st.subheader("Ø§Ù„ØªØ´ØºÙŠÙ„")
    limit = st.number_input("Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ø£ÙˆÙ„ N ØµÙ (0 = ÙƒÙ„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª)", min_value=0, value=min(20, len(df)), step=10)
    st.caption("Ø§Ø¨Ø¯Ø£ Ø¨Ù€ 20â€“50 Ù…Ù†ØªØ¬ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø© Ø«Ù… Ø²Ø¯ Ø§Ù„Ø¹Ø¯Ø¯ ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§.")

    run = st.button("ğŸš€ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„ÙˆØµÙ")

    if run:
        work_df = df.copy()
        if limit and limit > 0:
            work_df = work_df.head(int(limit))

        titles, descs = [], []

        if "cache" not in st.session_state:
            st.session_state["cache"] = {}
        cache = st.session_state["cache"]

        prog = st.progress(0.0)
        status = st.empty()

        total = len(work_df)
        for i, (_, r) in enumerate(work_df.iterrows(), start=1):
            row = {
                "raw_name": norm(r.get(col_name)),
                "brand": norm(r.get(col_brand)) if col_brand else "",
                "product_type": norm(r.get(col_type)) if col_type else "",
                "feature": norm(r.get(col_feature)) if col_feature else "",
                "size": norm(r.get(col_size)) if col_size else "",
                "unit": norm(r.get(col_unit)) if col_unit else "",
                "country": norm(r.get(col_country)) if col_country else "",
                "storage": norm(r.get(col_storage)) if col_storage else "",
                "uses": norm(r.get(col_uses)) if col_uses else "",
            }

            k = stable_key(row)
            if k in cache:
                data = cache[k]
            else:
                data = call_openai_structured(build_user_input(row))
                cache[k] = data

            titles.append(data["title"].strip())
            descs.append(data["description"].strip())

            prog.progress(i / total)
            status.write(f"ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© {i}/{total}")

        work_df["generated_title"] = titles
        work_df["generated_description"] = descs

        st.success("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ø£ÙˆØµØ§Ù!")
        st.dataframe(work_df.head(30), use_container_width=True)

        out_csv = work_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
        st.download_button(
            "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ CSV Ø§Ù„Ù†Ø§ØªØ¬",
            data=out_csv,
            file_name="products_out.csv",
            mime="text/csv",
        )
